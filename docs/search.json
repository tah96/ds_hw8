[
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "Modeling For Data Science",
    "section": "",
    "text": "We’ll first read in our libraries and our dataset of interest\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(parsnip)\nlibrary(lubridate)\nlibrary(see)\n\nbike_data &lt;- read_csv(file='data/SeoulBikeData.csv',show_col_types=FALSE)\nhead(bike_data)\n\n# A tibble: 6 × 14\n  Date       `Rented Bike Count`  Hour `Temperature(C)` `Humidity(%)`\n  &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 01/12/2017                 254     0             -5.2            37\n2 01/12/2017                 204     1             -5.5            38\n3 01/12/2017                 173     2             -6              39\n4 01/12/2017                 107     3             -6.2            40\n5 01/12/2017                  78     4             -6              36\n6 01/12/2017                 100     5             -6.4            37\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;"
  },
  {
    "objectID": "models.html#reading-in-libraries-and-our-data",
    "href": "models.html#reading-in-libraries-and-our-data",
    "title": "Modeling For Data Science",
    "section": "",
    "text": "We’ll first read in our libraries and our dataset of interest\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(parsnip)\nlibrary(lubridate)\nlibrary(see)\n\nbike_data &lt;- read_csv(file='data/SeoulBikeData.csv',show_col_types=FALSE)\nhead(bike_data)\n\n# A tibble: 6 × 14\n  Date       `Rented Bike Count`  Hour `Temperature(C)` `Humidity(%)`\n  &lt;chr&gt;                    &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 01/12/2017                 254     0             -5.2            37\n2 01/12/2017                 204     1             -5.5            38\n3 01/12/2017                 173     2             -6              39\n4 01/12/2017                 107     3             -6.2            40\n5 01/12/2017                  78     4             -6              36\n6 01/12/2017                 100     5             -6.4            37\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;dbl&gt;, `Visibility (10m)` &lt;dbl&gt;,\n#   `Dew point temperature(C)` &lt;dbl&gt;, `Solar Radiation (MJ/m2)` &lt;dbl&gt;,\n#   `Rainfall(mm)` &lt;dbl&gt;, `Snowfall (cm)` &lt;dbl&gt;, Seasons &lt;chr&gt;, Holiday &lt;chr&gt;,\n#   `Functioning Day` &lt;chr&gt;"
  },
  {
    "objectID": "models.html#exploratory-data-ananlyses",
    "href": "models.html#exploratory-data-ananlyses",
    "title": "Modeling For Data Science",
    "section": "Exploratory Data Ananlyses",
    "text": "Exploratory Data Ananlyses\nBefore building our models, we want to get familiar with our data and perform some non-transformative data transformations if needed.\nLets check for the missing values in our data…The good news is there are no missing values!\n\ncolSums(is.na(bike_data))\n\n                    Date        Rented Bike Count                     Hour \n                       0                        0                        0 \n          Temperature(C)              Humidity(%)         Wind speed (m/s) \n                       0                        0                        0 \n        Visibility (10m) Dew point temperature(C)  Solar Radiation (MJ/m2) \n                       0                        0                        0 \n            Rainfall(mm)            Snowfall (cm)                  Seasons \n                       0                        0                        0 \n                 Holiday          Functioning Day \n                       0                        0 \n\n\nLets check the column types to make sure they make sense along with some sample values. A few things we notice:\n\nDate is read in as character type. We will want to update this to numeric or date type\nThere are four Seasons. Winter, Sprint, Fall and Summer.\nHoliday and Functioning Day attributes could be used as boolean if needed. They only hold 2 values\n\n\nstr(bike_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                    : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count       : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                    : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)             : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)        : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)        : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2) : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)           : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                 : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                 : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day         : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nDiving a level further, lets make sure all of our numeric columns where we should only expect values greater than zero follow that pattern. We will also want to make sure our assumption on values for Seasons, Holiday and Functioning Day hold true.\nEverything seems to look good per the output below\n\nnumColsInterest &lt;- list(rented_bike &lt;- bike_data$`Rented Bike Count`,\n                        hour &lt;- bike_data$Hour,\n                        humid &lt;- bike_data$`Humidity(%)`,\n                        wind &lt;- bike_data$`Wind speed (m/s)`,\n                        vis &lt;- bike_data$`Visibility (10m)`,\n                        solar &lt;- bike_data$`Solar Radiation (MJ/m2)`,\n                        rain &lt;- bike_data$`Rainfall(mm)`,\n                        snow &lt;- bike_data$`Snowfall (cm)`\n                        \n)\n\ncatColsInterest &lt;- list(seasons_unique = unique(bike_data$Seasons),\n                        holiday_unique = unique(bike_data$Holiday),\n                        day_unique = unique(bike_data$`Functioning Day`))\n\ncatColsInterest\n\n$seasons_unique\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$holiday_unique\n[1] \"No Holiday\" \"Holiday\"   \n\n$day_unique\n[1] \"Yes\" \"No\" \n\nnumMins &lt;- lapply(numColsInterest,min)\nstr(numMins)\n\nList of 8\n $ : num 0\n $ : num 0\n $ : num 0\n $ : num 0\n $ : num 27\n $ : num 0\n $ : num 0\n $ : num 0\n\n\nWe want a series of transformations and renamings. We want the Date column in a data format. We want Seasons,Holiday,Functioning Day as factors. We also want to rename all of our columns so they’re easier to work with using camel_case format.\nWe can see everything reflected in our structure output.\n\nbike_data &lt;- bike_data %&gt;%\n  mutate(Date = dmy(Date),\n         Seasons = as.factor(Seasons),\n         Holiday = as.factor(Holiday),\n         `Functioning Day` = as.factor(`Functioning Day`)\n         ) %&gt;%\n  rename(date = Date,\n         rented_bike_count = `Rented Bike Count`,\n         hour = Hour,\n         temperature_c = `Temperature(C)`,\n         humidity_perc = `Humidity(%)`,\n         wind_speed_ms = `Wind speed (m/s)`,\n         visibility = `Visibility (10m)`,\n         dew_temp = `Dew point temperature(C)`,\n         solar_radiation = `Solar Radiation (MJ/m2)`,\n         rainfall_mm = `Rainfall(mm)`,\n         snowfall_cm = `Snowfall (cm)`,\n         season = Seasons,\n         holiday = Holiday,\n         func_day = `Functioning Day`\n         )\n\nstr(bike_data)\n\ntibble [8,760 × 14] (S3: tbl_df/tbl/data.frame)\n $ date             : Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" ...\n $ rented_bike_count: num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ hour             : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ temperature_c    : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ humidity_perc    : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ wind_speed_ms    : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ visibility       : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ dew_temp         : num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ solar_radiation  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ rainfall_mm      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ snowfall_cm      : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ season           : Factor w/ 4 levels \"Autumn\",\"Spring\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ holiday          : Factor w/ 2 levels \"Holiday\",\"No Holiday\": 2 2 2 2 2 2 2 2 2 2 ...\n $ func_day         : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n\n\nWe want to create some summary statistics. We want to look our our rented_bike_count across our categorical variables season, holiday and func_day.\n\nbike_summaries &lt;- list(general=NULL, season = NULL, holiday = NULL, func_day = NULL)\n\nsummarizeNumeric &lt;- function(data,catVar){\n  catSym &lt;- sym(catVar)\n  summary_data &lt;- bike_data %&gt;%\n    select(rented_bike_count,!!catSym) %&gt;%\n    group_by(!!catSym) %&gt;%\n    summarize(across(everything(), .fns = list(\"mean\" = mean,\n                                                 \"median\" = median,\n                                                 \"var\" = var,\n                                                 \"sd\" = sd,\n                                                 \"IQR\" = IQR), .names = \"{.fn}_{.col}\"))\n  return(summary_data)\n}\n\n\nbike_summaries$season &lt;- summarizeNumeric(bike_data,\"season\")\nbike_summaries$holiday &lt;- summarizeNumeric(bike_data,\"holiday\")\nbike_summaries$func_day &lt;- summarizeNumeric(bike_data,\"func_day\")\n\nbike_summaries$general &lt;- bike_data %&gt;%\n  select(rented_bike_count) %&gt;%\n  summarize(across(everything(), .fns = list(\"mean\" = mean,\n                                                 \"median\" = median,\n                                                 \"var\" = var,\n                                                 \"sd\" = sd,\n                                                 \"IQR\" = IQR), .names = \"{.fn}_{.col}\"))\n\nbike_summaries\n\n$general\n# A tibble: 1 × 5\n  mean_rented_bike_count median_rented_bike_count var_rented_bike_count\n                   &lt;dbl&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;\n1                   705.                     504.               416022.\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n$season\n# A tibble: 4 × 6\n  season mean_rented_bike_count median_rented_bike_count var_rented_bike_count\n  &lt;fct&gt;                   &lt;dbl&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;\n1 Autumn                   820.                     764.               423912.\n2 Spring                   730.                     583                386274.\n3 Summer                  1034.                     906.               476438.\n4 Winter                   226.                     203                 22612.\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n$holiday\n# A tibble: 2 × 6\n  holiday    mean_rented_bike_count median_rented_bike_c…¹ var_rented_bike_count\n  &lt;fct&gt;                       &lt;dbl&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;\n1 Holiday                      500.                   240                325782.\n2 No Holiday                   715.                   524.               418453.\n# ℹ abbreviated name: ¹​median_rented_bike_count\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n$func_day\n# A tibble: 2 × 6\n  func_day mean_rented_bike_count median_rented_bike_count var_rented_bike_count\n  &lt;fct&gt;                     &lt;dbl&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;\n1 No                           0                         0                    0 \n2 Yes                        729.                      542               412615.\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n\nOne major thing that stands out is no bikes are sold on a non-functioning day. This makes sense because a bike shop cannot sell bikes when it is closed. We will subset the data to only look at functioning days\n\nbike_data &lt;- bike_data %&gt;%\n  filter(func_day == \"Yes\")\n\nFor modeling and summaries later, we want to look at day-level granularity rather than hourly. Lets transform the data using dplyr to give us some appropriate aggregate measures of our weather related variables.\nWe’ll group by date, season and holiday.\n\nagg_bike_data &lt;- bike_data %&gt;%\n  group_by(date,season,holiday) %&gt;%\n  summarize(rented_bike_count= sum(rented_bike_count),\n            total_rainfall_mm = sum(rainfall_mm),\n            total_snowfall_cm = sum(snowfall_cm),\n            avg_temp_c = mean(temperature_c),\n            avg_humidity_perc = mean(humidity_perc),\n            avg_windspeed_ms = mean(wind_speed_ms),\n            avg_dew_temp = mean(dew_temp),\n            avg_solar_radiation = mean(solar_radiation),\n            avg_visibility = mean(visibility)\n            )\n\n`summarise()` has grouped output by 'date', 'season'. You can override using\nthe `.groups` argument.\n\nhead(agg_bike_data)\n\n# A tibble: 6 × 12\n# Groups:   date, season [6]\n  date       season holiday    rented_bike_count total_rainfall_mm\n  &lt;date&gt;     &lt;fct&gt;  &lt;fct&gt;                  &lt;dbl&gt;             &lt;dbl&gt;\n1 2017-12-01 Winter No Holiday              9539               0  \n2 2017-12-02 Winter No Holiday              8523               0  \n3 2017-12-03 Winter No Holiday              7222               4  \n4 2017-12-04 Winter No Holiday              8729               0.1\n5 2017-12-05 Winter No Holiday              8307               0  \n6 2017-12-06 Winter No Holiday              6669               1.3\n# ℹ 7 more variables: total_snowfall_cm &lt;dbl&gt;, avg_temp_c &lt;dbl&gt;,\n#   avg_humidity_perc &lt;dbl&gt;, avg_windspeed_ms &lt;dbl&gt;, avg_dew_temp &lt;dbl&gt;,\n#   avg_solar_radiation &lt;dbl&gt;, avg_visibility &lt;dbl&gt;\n\n\nLets recreate our basic summary tables from the previous steps using this data. There is no need to do this for func_day anymore since there is only one value after our previous subsetting\n\nagg_bike_summaries &lt;- list(general=NULL, season = NULL, holiday = NULL)\n\nagg_bike_summaries$season &lt;- summarizeNumeric(agg_bike_data,\"season\")\nagg_bike_summaries$holiday &lt;- summarizeNumeric(agg_bike_data,\"holiday\")\n\nagg_bike_summaries$general &lt;- agg_bike_data %&gt;%\n  select(rented_bike_count) %&gt;%\n  summarize(across(everything(), .fns = list(\"mean\" = mean,\n                                                 \"median\" = median,\n                                                 \"var\" = var,\n                                                 \"sd\" = sd,\n                                                 \"IQR\" = IQR), .names = \"{.fn}_{.col}\"))\n\nAdding missing grouping variables: `date`, `season`\n`summarise()` has grouped output by 'date'. You can override using the\n`.groups` argument.\n\nagg_bike_summaries\n\n$general\n# A tibble: 353 × 7\n# Groups:   date [353]\n   date       season mean_rented_bike_count median_rented_bike_count\n   &lt;date&gt;     &lt;fct&gt;                   &lt;dbl&gt;                    &lt;dbl&gt;\n 1 2017-12-01 Winter                   9539                     9539\n 2 2017-12-02 Winter                   8523                     8523\n 3 2017-12-03 Winter                   7222                     7222\n 4 2017-12-04 Winter                   8729                     8729\n 5 2017-12-05 Winter                   8307                     8307\n 6 2017-12-06 Winter                   6669                     6669\n 7 2017-12-07 Winter                   8549                     8549\n 8 2017-12-08 Winter                   8032                     8032\n 9 2017-12-09 Winter                   7233                     7233\n10 2017-12-10 Winter                   3453                     3453\n# ℹ 343 more rows\n# ℹ 3 more variables: var_rented_bike_count &lt;dbl&gt;, sd_rented_bike_count &lt;dbl&gt;,\n#   IQR_rented_bike_count &lt;dbl&gt;\n\n$season\n# A tibble: 4 × 6\n  season mean_rented_bike_count median_rented_bike_count var_rented_bike_count\n  &lt;fct&gt;                   &lt;dbl&gt;                    &lt;dbl&gt;                 &lt;dbl&gt;\n1 Autumn                   924.                     856                381365.\n2 Spring                   746.                     599                382750.\n3 Summer                  1034.                     906.               476438.\n4 Winter                   226.                     203                 22612.\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n$holiday\n# A tibble: 2 × 6\n  holiday    mean_rented_bike_count median_rented_bike_c…¹ var_rented_bike_count\n  &lt;fct&gt;                       &lt;dbl&gt;                  &lt;dbl&gt;                 &lt;dbl&gt;\n1 Holiday                      529.                    259               329398.\n2 No Holiday                   739.                    561               414742.\n# ℹ abbreviated name: ¹​median_rented_bike_count\n# ℹ 2 more variables: sd_rented_bike_count &lt;dbl&gt;, IQR_rented_bike_count &lt;dbl&gt;\n\n\nWe want to explore some relationships we’re curious about and visualize them in plots. There are more than a dozen we can explore, but for the purpose of keeping this concise you can the following plots an their observations.\n\nScatter plot between rented bikes and the average temperature colored by season. We notice a positive correlation and obvious grouping of temperatures based on season. This is expected.\nScatter plot between rented bikes and the average solar radiation colored by season. We notice a positive correlation and obvious grouping of solar radiation based on season. This is expected.\nDensity plot for units sold colored by season. We see a larger spread for most seasons except for winter which seems to hold a smaller spread of units sold by day.\nBoxplot for visibility across season. We observe boxplots with somewhat spread, but spring seems to have a lower median that others indicating lower visibility. Perhaps this is due to fog in the spring.\n\n\nsales_temp_scatter &lt;- ggplot(agg_bike_data,aes(x=avg_temp_c,y=rented_bike_count,color=season)) +\n  geom_point() +\n  labs(title='Temp & Units Rented Plot colored by Season') +\n  xlab('Temperature (C)') +\n  ylab('Bikes Rented')\n\nsales_radiation_scatter &lt;- ggplot(agg_bike_data,aes(x=avg_solar_radiation,y=rented_bike_count,color=season)) +\n  geom_point() +\n  labs(title='Radiation & Units Rented Plot colored by Season') +\n  xlab('Radiation') +\n  ylab('Bikes Rented')\n\nseason_sales_dens &lt;-\n  ggplot(agg_bike_data,aes(x=rented_bike_count)) +\n  geom_density(aes(fill=season),alpha=0.6) +\n  labs(title = 'Density plot of Unit sales over seasons',fill = 'Season') +\n  xlab('Units Rented') +\n  ylab('Density')\n\nseason_visibility_box &lt;- ggplot(agg_bike_data, aes(x=season, y= avg_visibility)) +\n  geom_boxplot(varwidth=T, fill=\"lightblue\") + \n  labs(title=\"Visibility by Season Box\", \n       x=\"Season\",\n       y=\"Visibility\")\n  \n\nsales_temp_scatter\n\n\n\nsales_radiation_scatter\n\n\n\nseason_sales_dens\n\n\n\nseason_visibility_box\n\n\n\n\nWe want to calculate some correlations. You can read the output below as a correlation matrix. Some notable relationships include…\n\n0.75 correlation value between the bike count and the average temperature for that day\n0.735 correlation value between the bike count and the average solar radiation for that day\nWeak but negative correlation (~-0.25) for rainfall, snow and wind against bike count.\n\nAll of these loosely point to more sales on warm and sunny days!\n\nnumeric_vars &lt;- agg_bike_data %&gt;% \n  ungroup() %&gt;%\n  select(where(is.numeric))\n\ncor(numeric_vars)\n\n                    rented_bike_count total_rainfall_mm total_snowfall_cm\nrented_bike_count          1.00000000       -0.23910905       -0.26529110\ntotal_rainfall_mm         -0.23910905        1.00000000       -0.02313404\ntotal_snowfall_cm         -0.26529110       -0.02313404        1.00000000\navg_temp_c                 0.75307673        0.14451727       -0.26696366\navg_humidity_perc          0.03588697        0.52864263        0.06539191\navg_windspeed_ms          -0.19288142       -0.10167578        0.02088156\navg_dew_temp               0.65047655        0.26456621       -0.20955286\navg_solar_radiation        0.73589290       -0.32270413       -0.23343056\navg_visibility             0.16599375       -0.22199387       -0.10188902\n                      avg_temp_c avg_humidity_perc avg_windspeed_ms\nrented_bike_count    0.753076732        0.03588697      -0.19288142\ntotal_rainfall_mm    0.144517274        0.52864263      -0.10167578\ntotal_snowfall_cm   -0.266963662        0.06539191       0.02088156\navg_temp_c           1.000000000        0.40416749      -0.26072179\navg_humidity_perc    0.404167486        1.00000000      -0.23425778\navg_windspeed_ms    -0.260721792       -0.23425778       1.00000000\navg_dew_temp         0.962796255        0.63204729      -0.28770322\navg_solar_radiation  0.550274301       -0.27444967       0.09612635\navg_visibility       0.002336683       -0.55917733       0.20602264\n                    avg_dew_temp avg_solar_radiation avg_visibility\nrented_bike_count      0.6504765          0.73589290    0.165993749\ntotal_rainfall_mm      0.2645662         -0.32270413   -0.221993866\ntotal_snowfall_cm     -0.2095529         -0.23343056   -0.101889019\navg_temp_c             0.9627963          0.55027430    0.002336683\navg_humidity_perc      0.6320473         -0.27444967   -0.559177334\navg_windspeed_ms      -0.2877032          0.09612635    0.206022636\navg_dew_temp           1.0000000          0.38315713   -0.153551591\navg_solar_radiation    0.3831571          1.00000000    0.271395906\navg_visibility        -0.1535516          0.27139591    1.000000000"
  },
  {
    "objectID": "models.html#modeling",
    "href": "models.html#modeling",
    "title": "Modeling For Data Science",
    "section": "Modeling",
    "text": "Modeling\nNow that we’ve done some exploratory analysis, lets get started on our model creation. First we’ll split our data in test and training sets (seasons as strata). We’ll also split our training set in folds for cross-validation.\nWe can see our split is 75/25 (training/testing) and that there are 10 folds in our training set in the output below.\n\nbike_split &lt;- initial_split(agg_bike_data,prop=0.75,strata=season)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\nbike_train_10_fold &lt;- vfold_cv(bike_train,10)\n\nbike_split\n\n&lt;Training/Testing/Total&gt;\n&lt;263/90/353&gt;\n\nbike_train_10_fold\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits           id    \n   &lt;list&gt;           &lt;chr&gt; \n 1 &lt;split [236/27]&gt; Fold01\n 2 &lt;split [236/27]&gt; Fold02\n 3 &lt;split [236/27]&gt; Fold03\n 4 &lt;split [237/26]&gt; Fold04\n 5 &lt;split [237/26]&gt; Fold05\n 6 &lt;split [237/26]&gt; Fold06\n 7 &lt;split [237/26]&gt; Fold07\n 8 &lt;split [237/26]&gt; Fold08\n 9 &lt;split [237/26]&gt; Fold09\n10 &lt;split [237/26]&gt; Fold10\n\n\nLets construct three recipes. For each recipe, we’ll factor our dates to either “Weekday” or “Weekend” depending on the day of the week. We’ll also normalize our numeric variables and create dummy variables for our categoricals.\nHere’s where our 3 models different slightly: 1. Recipe 1 is exactly as described above with no additional changes 2. Recipe 2 adds interactions between holiday & seasons, seasons & temperature, and temperature & rainfall 3. Recipe 3 includes everything in Recipe 2 with the added complexity of our numeric predictors having quadratic terms.\n\nrecipe_1 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date,features=c(\"dow\")) |&gt;\n  step_mutate(date_dow = factor(date_dow,levels=unique(date_dow),labels=if_else(unique(date_dow) %in% c('Mon','Tue','Wed','Thu','Fri'),\"Weekday\",\"Weekend\"))) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(season,holiday,date_dow)\n\nrecipe_2 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date,features=c(\"dow\")) |&gt;\n  step_mutate(date_dow = factor(date_dow,levels=unique(date_dow),labels=if_else(unique(date_dow) %in% c('Mon','Tue','Wed','Thu','Fri'),\"Weekday\",\"Weekend\"))) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_dummy(season,holiday,date_dow) |&gt;\n  step_interact(terms = ~ starts_with(\"season\"):starts_with(\"holiday\") + \n                  starts_with(\"season\"):avg_temp_c +\n                  avg_temp_c:total_rainfall_mm)\n\nrecipe_3 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  update_role(date, new_role = \"ID\") |&gt;\n  step_date(date,features=c(\"dow\")) |&gt;\n  step_mutate(date_dow = factor(date_dow,levels=unique(date_dow),labels=if_else(unique(date_dow) %in% c('Mon','Tue','Wed','Thu','Fri'),\"Weekday\",\"Weekend\"))) |&gt;\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  step_poly(all_numeric_predictors(), degree = 2, keep_original_cols = FALSE) |&gt;\n  step_dummy(season,holiday,date_dow) |&gt;\n  step_interact(terms = ~ starts_with(\"season\"):starts_with(\"holiday\") + \n                  starts_with(\"season\"):avg_temp_c_poly_1 +\n                  avg_temp_c_poly_1:total_rainfall_mm_poly_1)\n\nrecipe_1\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\nID:         1\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(date_dow, levels = unique(date_dow), labels =\n  if_else(unique(date_dow) %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n  \"Weekday\", \"Weekend\"))\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n• Dummy variables from: season, holiday, date_dow\n\nrecipe_2\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\nID:         1\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(date_dow, levels = unique(date_dow), labels =\n  if_else(unique(date_dow) %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n  \"Weekday\", \"Weekend\"))\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n• Dummy variables from: season, holiday, date_dow\n\n\n• Interactions with: ...\n\nrecipe_3\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\nID:         1\n\n\n\n\n\n── Operations \n\n\n• Date features from: date\n\n\n• Variable mutation for: factor(date_dow, levels = unique(date_dow), labels =\n  if_else(unique(date_dow) %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n  \"Weekday\", \"Weekend\"))\n\n\n• Centering and scaling for: all_numeric() and -all_outcomes()\n\n\n• Orthogonal polynomials on: all_numeric_predictors()\n\n\n• Dummy variables from: season, holiday, date_dow\n\n\n• Interactions with: ...\n\n\nNow that we’ve got our recipe, lets set up a linear regression model and use the “lm” engine\n\nbike_mod &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nbike_mod\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\nWe’ll use our 10 fold CV training set in our models with each recipe. Before doing this we need to create our individual workflows to collect metrics.\nLooking at our CV error (2 for each), we see that our third model (interactions & polynomials) is our best model with the lowest RMSE of ~2959!\n\nbike_wfl_1 &lt;- workflow() |&gt;\n  add_recipe(recipe_1) |&gt;\n  add_model(bike_mod)\n  \nbike_fit_1 &lt;- bike_wfl_1 |&gt;\n  fit_resamples(bike_train_10_fold)\n\nbike_wfl_2 &lt;- workflow() |&gt;\n  add_recipe(recipe_2) |&gt;\n  add_model(bike_mod)\n\nbike_fit_2 &lt;- bike_wfl_2 |&gt;\n  fit_resamples(bike_train_10_fold)\n\nbike_wfl_3 &lt;- workflow() |&gt;\n  add_recipe(recipe_3) |&gt;\n  add_model(bike_mod)\n\nbike_fit_3 &lt;- bike_wfl_3 |&gt;\n  fit_resamples(bike_train_10_fold)\n\nrbind(bike_fit_1 |&gt; collect_metrics(),bike_fit_2 |&gt; collect_metrics(),bike_fit_3 |&gt; collect_metrics())\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4122.       10 153.     Preprocessor1_Model1\n2 rsq     standard      0.828    10   0.0156 Preprocessor1_Model1\n3 rmse    standard   3007.       10 264.     Preprocessor1_Model1\n4 rsq     standard      0.905    10   0.0201 Preprocessor1_Model1\n5 rmse    standard   2976.       10 278.     Preprocessor1_Model1\n6 rsq     standard      0.907    10   0.0202 Preprocessor1_Model1\n\n\nSince our interaction and polynomial model is our best model, we want to keep this, evaluate against our entire training set and test against our test set.\nOur RMSE evaluated against our test data is ~2859. We can also see our coefficients from the fitted model in the second output module.\n\ntest_metrics &lt;- bike_wfl_3 |&gt;\n  last_fit(bike_split) |&gt;\n  collect_metrics()\n\nfinal_model &lt;- bike_wfl_3 |&gt;\n  fit(bike_train) |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\ntest_metrics\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3311.    Preprocessor1_Model1\n2 rsq     standard       0.895 Preprocessor1_Model1\n\nfinal_model\n\n# A tibble: 29 × 5\n   term                     estimate std.error statistic  p.value\n   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                17774.     2141.    8.30   8.14e-15\n 2 total_rainfall_mm_poly_1  -22318.     6932.   -3.22   1.47e- 3\n 3 total_rainfall_mm_poly_2    9961.     3456.    2.88   4.32e- 3\n 4 total_snowfall_cm_poly_1   -2298.     3216.   -0.715  4.76e- 1\n 5 total_snowfall_cm_poly_2   -1611.     3075.   -0.524  6.01e- 1\n 6 avg_temp_c_poly_1          -8756.    72589.   -0.121  9.04e- 1\n 7 avg_temp_c_poly_2          -2971.    17465.   -0.170  8.65e- 1\n 8 avg_humidity_perc_poly_1  -40627.    24305.   -1.67   9.60e- 2\n 9 avg_humidity_perc_poly_2    -604.     6076.   -0.0994 9.21e- 1\n10 avg_windspeed_ms_poly_1    -8286.     3302.   -2.51   1.28e- 2\n# ℹ 19 more rows"
  }
]